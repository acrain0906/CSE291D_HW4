{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, DistanceMetric\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "%config InlineBackend.figure_format='svg'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readMNIST (filename):\n",
    "    data = np.genfromtxt(filename, delimiter = \",\")\n",
    "    data = data.transpose()\n",
    "    \n",
    "    label = np.array(data[:, -1])\n",
    "    feature = np.array(data[:,:-1])\n",
    "    \n",
    "    return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST data... done.\n"
     ]
    }
   ],
   "source": [
    "sys.stdout.write('Loading MNIST data... ')\n",
    "MNIST_train_feature, MNIST_train_label = readMNIST('./MNIST/train.csv')\n",
    "MNIST_test_feature, MNIST_test_label = readMNIST('./MNIST/test.csv')\n",
    "print ('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split MNIST into specific outputs... done.\n"
     ]
    }
   ],
   "source": [
    "sys.stdout.write('Split MNIST into specific outputs... ')\n",
    "# split into 0, 1, 3, 5\n",
    "#   1) zip labels and features together\n",
    "MNIST_train_list = list(zip(MNIST_train_feature, MNIST_train_label))\n",
    "MNIST_test_list = list(zip(MNIST_test_feature, MNIST_test_label))\n",
    "print ('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle (featurelist, labellist):\n",
    "    merged = list(zip(featurelist, labellist))\n",
    "    random.shuffle(merged)\n",
    "    featurelist, labellist = zip(*merged)\n",
    "    return np.array(featurelist), np.array(labellist)\n",
    "\n",
    "def mergeAndShuffle(list1, list2):\n",
    "    featurelist = []\n",
    "    labellist = []\n",
    "    for (feature, label) in list1:\n",
    "        featurelist.append(feature)\n",
    "        labellist.append(label)\n",
    "    for (feature, label) in list2:\n",
    "        featurelist.append(feature)\n",
    "        labellist.append(label)\n",
    "    return shuffle (featurelist, labellist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ising Model Gibbs Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature, label = mergeAndShuffle(MNIST_test_list, MNIST_train_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to binary matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = feature > feature.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotGrayScale(im):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(im.reshape(28, 28), aspect='auto', cmap=plt.cm.gray, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotGrayScale(feature_new[105])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flip = np.random.random(feature.shape) > .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = np.logical_or(np.logical_and(flip, np.logical_not(feature)), np.logical_and(feature, np.logical_not(flip)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotGrayScale(feature[16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7058\n"
     ]
    }
   ],
   "source": [
    "quarter = int (label.shape[0] / 4)\n",
    "test_feature = feature[:quarter]\n",
    "train_feature = feature[quarter:]\n",
    "\n",
    "test_label = label[:quarter]\n",
    "train_label = label[quarter:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5294\n"
     ]
    }
   ],
   "source": [
    "# Randomly select a subset of d% from the training data where d={50,75,100}.\n",
    "# Generate five training sets for each of the d% data, the 100% case however will just have one set.\n",
    "quarter = int (train_label.shape[0] / 4)\n",
    "\n",
    "train_data = [random.sample (list(zip(train_feature, train_label)), i * quarter) for i in [2, 3, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// naive gibbs sampler for the ising model\n",
    "x = randomState()\n",
    "while true:\n",
    "\t// calculate probability of this state and a proposal\n",
    "\tpx = pi(x) // pi is the un-normalized probability as defined above\n",
    "\txnew = flipOneBit(x)\n",
    "\tpnew = pi(xnew)\n",
    "\n",
    "\t// calculate transition probability alpha\n",
    "\ttransitionProbability = min(1, pnew/px)\n",
    "\tif uniformRandom(0,1) < transitionProbability:\n",
    "\t\tx = xnew // transition to x'!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['sci.space', 'talk.religion.misc','rec.motorcycles']\n",
    "newsgroups_train = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(strip_accents='unicode', stop_words = 'english')\n",
    "vectors = vec.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "V = len(vec.vocabulary_)\n",
    "K = 3\n",
    "theta = np.zeros((K,V))\n",
    "beta = np.ones(V)\n",
    "alpha = np.ones(K)*0.1\n",
    "\n",
    "for i in range(K):\n",
    "    theta[i] = np.random.dirichlet(beta)\n",
    "    \n",
    "pi = np.random.dirichlet(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numdocs = vectors.shape[0]\n",
    "Z = np.random.choice(K,numdocs,p=pi)\n",
    "classcounts = np.bincount(Z)\n",
    "classwordcounts = np.zeros((K,V))\n",
    "for document in xrange(numdocs):\n",
    "    classwordcounts[Z[document]]+=vectors[document]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Update Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateZ(Zold, theta, pi):\n",
    "    Zret= []\n",
    "    for document in xrange(numdocs):\n",
    "        probs = np.zeros(K)\n",
    "        for i in range(K):\n",
    "            probs[i] = pi[i]\n",
    "            probs[i]*=np.prod(np.power(theta[i],np.array(vectors[document].todense())))\n",
    "        probs+=np.ones(K)*10**(-200)\n",
    "        probs = probs/np.sum(probs)\n",
    "        Znew = np.random.choice(K,p=probs)\n",
    "        if Znew!=Zold[document]:\n",
    "            classcounts[Zold[document]]-=1\n",
    "            classcounts[Znew]+=1\n",
    "            classwordcounts[Zold[document]]-=vectors[document]\n",
    "            classwordcounts[Znew]+=vectors[document]\n",
    "        Zret.append(Znew)\n",
    "    return np.array(Zret),classwordcounts,classcounts\n",
    "\n",
    "def updatetheta(beta,classwordcounts):\n",
    "    for i in range(K):\n",
    "        theta[i] = np.random.dirichlet(beta + classwordcounts[i])\n",
    "    return theta\n",
    "\n",
    "def updatepi(alpha, classcounts):\n",
    "    return np.random.dirichlet(alpha+classcounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Gibbs Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for it in range(40):\n",
    "    pi = updatepi(alpha,classcounts)\n",
    "    theta = updatetheta(beta,classwordcounts)\n",
    "    Z,classwordcounts,classcounts = updateZ(Z, theta, pi)\n",
    "    print it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = theta[1].argsort()\n",
    "wordvocab = [(vec.vocabulary_[k],k) for k in vec.vocabulary_]\n",
    "wordvocab = dict(wordvocab)\n",
    "for x in a[-10:]:\n",
    "    print wordvocab[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assignment: \n",
    "#   \n",
    "\n",
    "# Data Located at:\n",
    "#   http://yann.lecun.com/exdb/mnist/\n",
    "#   http://cis.jhu.edu/~sachin/digit/digit.html\n",
    "\n",
    "\n",
    "# Bugs:\n",
    "# Descrition: \n",
    "#   solution:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
